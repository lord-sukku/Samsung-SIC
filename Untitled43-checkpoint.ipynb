{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5cc70635",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import pandas as pd\n",
    "\n",
    "# def compile_annotations_to_csv(main_folder, output_csv_path):\n",
    "#     # Categories of your dataset\n",
    "#     categories = ['DRUSEN', 'CNV']\n",
    "\n",
    "#     # Initialize a list to store annotations\n",
    "#     annotations = []\n",
    "\n",
    "#     for category in categories:\n",
    "#         category_path = os.path.join(main_folder, category)\n",
    "        \n",
    "#         # Loop through each image file in the category folder\n",
    "#         for image_file in os.listdir(category_path):\n",
    "#             if image_file.endswith(('.jpg', '.jpeg', '.png')):\n",
    "#                 image_path = os.path.join(category_path, image_file)\n",
    "                \n",
    "#                 # Hypothetical annotations for each image\n",
    "#                 # In a real scenario, replace this with code to read actual annotations\n",
    "#                 # Example: annotations for one object per image\n",
    "#                 annotations.append({'image_path': image_path, \n",
    "#                                     'x_min': 25, 'y_min': 30, \n",
    "#                                     'x_max': 100, 'y_max': 150, \n",
    "#                                     'class': category})\n",
    "\n",
    "#                 # If you have multiple objects per image, you would loop through them here\n",
    "#                 # For example:\n",
    "# #                 for obj in get_annotations_for_image(image_path):\n",
    "# #                     annotations.append({'image_path': image_path, \n",
    "# #                                         'x_min': obj['x_min'], 'y_min': obj['y_min'], \n",
    "# #                                         'x_max': obj['x_max'], 'y_max': obj['y_max'], \n",
    "# #                                         'class': category})\n",
    "\n",
    "#     # Create a DataFrame from the annotations list\n",
    "#     df = pd.DataFrame(annotations)\n",
    "\n",
    "#     # Save the DataFrame to a CSV file\n",
    "#     df.to_csv(output_csv_path, index=False)\n",
    "\n",
    "# # Example usage\n",
    "# main_folder = \"C:/Users/Sukku/Desktop/octsamsung\"\n",
    "# output_csv_path = 'path_to_output_annotations.csv'\n",
    "# compile_annotations_to_csv(main_folder, output_csv_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3bf2a06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a61f6d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def compile_annotations_to_csv(main_folder, output_csv_path):\n",
    "    # Categories of your dataset\n",
    "    categories = ['DRUSEN', 'CNV']\n",
    "\n",
    "    # Initialize a list to store annotations\n",
    "    annotations = []\n",
    "\n",
    "    for category in categories:\n",
    "        category_path = os.path.join(main_folder, category)\n",
    "        \n",
    "        # Loop through each image file in the category folder\n",
    "        for image_file in os.listdir(category_path):\n",
    "            if image_file.endswith(('.jpg', '.jpeg', '.png')):\n",
    "                image_path = os.path.join(category_path, image_file)\n",
    "                \n",
    "                # Hypothetical annotations for each image\n",
    "                # In a real scenario, replace this with code to read actual annotations\n",
    "                annotations.append({'image_path': image_path, \n",
    "                                    'x_min': 25, 'y_min': 30, \n",
    "                                    'x_max': 100, 'y_max': 150, \n",
    "                                    'class': category})\n",
    "\n",
    "    # Check if there are any annotations to process\n",
    "    if annotations:\n",
    "        # Create a DataFrame from the annotations list\n",
    "        df = pd.DataFrame(annotations)\n",
    "\n",
    "        # Save the DataFrame to a CSV file\n",
    "        df.to_csv(output_csv_path, index=False)\n",
    "    else:\n",
    "        print(\"No annotations found to compile into CSV.\")\n",
    "\n",
    "# Example usage\n",
    "main_folder = \"C:/Users/Sukku/Desktop/octsamsung\"  # Replace with your actual folder path\n",
    "output_csv_path = 'path_to_output_annotations.csv'  # Path where you want to save the CSV\n",
    "compile_annotations_to_csv(main_folder, output_csv_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d22ad9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv('path_to_output_annotations.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d3b3353e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_path</th>\n",
       "      <th>x_min</th>\n",
       "      <th>y_min</th>\n",
       "      <th>x_max</th>\n",
       "      <th>y_max</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C:/Users/Sukku/Desktop/octsamsung\\DRUSEN\\druse...</td>\n",
       "      <td>25</td>\n",
       "      <td>30</td>\n",
       "      <td>100</td>\n",
       "      <td>150</td>\n",
       "      <td>DRUSEN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C:/Users/Sukku/Desktop/octsamsung\\DRUSEN\\druse...</td>\n",
       "      <td>25</td>\n",
       "      <td>30</td>\n",
       "      <td>100</td>\n",
       "      <td>150</td>\n",
       "      <td>DRUSEN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C:/Users/Sukku/Desktop/octsamsung\\DRUSEN\\druse...</td>\n",
       "      <td>25</td>\n",
       "      <td>30</td>\n",
       "      <td>100</td>\n",
       "      <td>150</td>\n",
       "      <td>DRUSEN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C:/Users/Sukku/Desktop/octsamsung\\DRUSEN\\druse...</td>\n",
       "      <td>25</td>\n",
       "      <td>30</td>\n",
       "      <td>100</td>\n",
       "      <td>150</td>\n",
       "      <td>DRUSEN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C:/Users/Sukku/Desktop/octsamsung\\DRUSEN\\druse...</td>\n",
       "      <td>25</td>\n",
       "      <td>30</td>\n",
       "      <td>100</td>\n",
       "      <td>150</td>\n",
       "      <td>DRUSEN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>684</th>\n",
       "      <td>C:/Users/Sukku/Desktop/octsamsung\\CNV\\cnv_test...</td>\n",
       "      <td>25</td>\n",
       "      <td>30</td>\n",
       "      <td>100</td>\n",
       "      <td>150</td>\n",
       "      <td>CNV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>685</th>\n",
       "      <td>C:/Users/Sukku/Desktop/octsamsung\\CNV\\cnv_test...</td>\n",
       "      <td>25</td>\n",
       "      <td>30</td>\n",
       "      <td>100</td>\n",
       "      <td>150</td>\n",
       "      <td>CNV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>686</th>\n",
       "      <td>C:/Users/Sukku/Desktop/octsamsung\\CNV\\cnv_test...</td>\n",
       "      <td>25</td>\n",
       "      <td>30</td>\n",
       "      <td>100</td>\n",
       "      <td>150</td>\n",
       "      <td>CNV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>687</th>\n",
       "      <td>C:/Users/Sukku/Desktop/octsamsung\\CNV\\cnv_test...</td>\n",
       "      <td>25</td>\n",
       "      <td>30</td>\n",
       "      <td>100</td>\n",
       "      <td>150</td>\n",
       "      <td>CNV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688</th>\n",
       "      <td>C:/Users/Sukku/Desktop/octsamsung\\CNV\\cnv_test...</td>\n",
       "      <td>25</td>\n",
       "      <td>30</td>\n",
       "      <td>100</td>\n",
       "      <td>150</td>\n",
       "      <td>CNV</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>689 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            image_path  x_min  y_min  x_max  \\\n",
       "0    C:/Users/Sukku/Desktop/octsamsung\\DRUSEN\\druse...     25     30    100   \n",
       "1    C:/Users/Sukku/Desktop/octsamsung\\DRUSEN\\druse...     25     30    100   \n",
       "2    C:/Users/Sukku/Desktop/octsamsung\\DRUSEN\\druse...     25     30    100   \n",
       "3    C:/Users/Sukku/Desktop/octsamsung\\DRUSEN\\druse...     25     30    100   \n",
       "4    C:/Users/Sukku/Desktop/octsamsung\\DRUSEN\\druse...     25     30    100   \n",
       "..                                                 ...    ...    ...    ...   \n",
       "684  C:/Users/Sukku/Desktop/octsamsung\\CNV\\cnv_test...     25     30    100   \n",
       "685  C:/Users/Sukku/Desktop/octsamsung\\CNV\\cnv_test...     25     30    100   \n",
       "686  C:/Users/Sukku/Desktop/octsamsung\\CNV\\cnv_test...     25     30    100   \n",
       "687  C:/Users/Sukku/Desktop/octsamsung\\CNV\\cnv_test...     25     30    100   \n",
       "688  C:/Users/Sukku/Desktop/octsamsung\\CNV\\cnv_test...     25     30    100   \n",
       "\n",
       "     y_max   class  \n",
       "0      150  DRUSEN  \n",
       "1      150  DRUSEN  \n",
       "2      150  DRUSEN  \n",
       "3      150  DRUSEN  \n",
       "4      150  DRUSEN  \n",
       "..     ...     ...  \n",
       "684    150     CNV  \n",
       "685    150     CNV  \n",
       "686    150     CNV  \n",
       "687    150     CNV  \n",
       "688    150     CNV  \n",
       "\n",
       "[689 rows x 6 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5484a90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load your combined annotations into a DataFrame\n",
    "annotations_df = pd.read_csv('path_to_output_annotations.csv')\n",
    "\n",
    "# First split: Split the dataset into training (70%) and a temporary test set (30%)\n",
    "train_df, temp_test_df = train_test_split(annotations_df, test_size=0.3, random_state=42)\n",
    "\n",
    "# Second split: Split the temporary test set into test (20% of the original dataset) and validation sets (10% of the original dataset)\n",
    "# Note: To get 20% test and 10% validation from the remaining 30%, we use 2/3 (approx 0.67) split for the test set.\n",
    "test_df, val_df = train_test_split(temp_test_df, test_size=1/3, random_state=42)\n",
    "\n",
    "# Save these splits to new CSV files\n",
    "train_df.to_csv('train_annotations.csv', index=False)\n",
    "test_df.to_csv('test_annotations.csv', index=False)\n",
    "val_df.to_csv('val_annotations.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "fe4f5d0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_path</th>\n",
       "      <th>x_min</th>\n",
       "      <th>y_min</th>\n",
       "      <th>x_max</th>\n",
       "      <th>y_max</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C:/Users/Sukku/Desktop/octsamsung\\DRUSEN\\druse...</td>\n",
       "      <td>25</td>\n",
       "      <td>30</td>\n",
       "      <td>100</td>\n",
       "      <td>150</td>\n",
       "      <td>DRUSEN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C:/Users/Sukku/Desktop/octsamsung\\DRUSEN\\druse...</td>\n",
       "      <td>25</td>\n",
       "      <td>30</td>\n",
       "      <td>100</td>\n",
       "      <td>150</td>\n",
       "      <td>DRUSEN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C:/Users/Sukku/Desktop/octsamsung\\CNV\\cnv_test...</td>\n",
       "      <td>25</td>\n",
       "      <td>30</td>\n",
       "      <td>100</td>\n",
       "      <td>150</td>\n",
       "      <td>CNV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C:/Users/Sukku/Desktop/octsamsung\\CNV\\cnv_test...</td>\n",
       "      <td>25</td>\n",
       "      <td>30</td>\n",
       "      <td>100</td>\n",
       "      <td>150</td>\n",
       "      <td>CNV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C:/Users/Sukku/Desktop/octsamsung\\CNV\\cnv_test...</td>\n",
       "      <td>25</td>\n",
       "      <td>30</td>\n",
       "      <td>100</td>\n",
       "      <td>150</td>\n",
       "      <td>CNV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>C:/Users/Sukku/Desktop/octsamsung\\DRUSEN\\druse...</td>\n",
       "      <td>25</td>\n",
       "      <td>30</td>\n",
       "      <td>100</td>\n",
       "      <td>150</td>\n",
       "      <td>DRUSEN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>C:/Users/Sukku/Desktop/octsamsung\\DRUSEN\\druse...</td>\n",
       "      <td>25</td>\n",
       "      <td>30</td>\n",
       "      <td>100</td>\n",
       "      <td>150</td>\n",
       "      <td>DRUSEN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>C:/Users/Sukku/Desktop/octsamsung\\DRUSEN\\druse...</td>\n",
       "      <td>25</td>\n",
       "      <td>30</td>\n",
       "      <td>100</td>\n",
       "      <td>150</td>\n",
       "      <td>DRUSEN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>C:/Users/Sukku/Desktop/octsamsung\\CNV\\cnv_test...</td>\n",
       "      <td>25</td>\n",
       "      <td>30</td>\n",
       "      <td>100</td>\n",
       "      <td>150</td>\n",
       "      <td>CNV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>C:/Users/Sukku/Desktop/octsamsung\\DRUSEN\\druse...</td>\n",
       "      <td>25</td>\n",
       "      <td>30</td>\n",
       "      <td>100</td>\n",
       "      <td>150</td>\n",
       "      <td>DRUSEN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>482 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            image_path  x_min  y_min  x_max  \\\n",
       "0    C:/Users/Sukku/Desktop/octsamsung\\DRUSEN\\druse...     25     30    100   \n",
       "1    C:/Users/Sukku/Desktop/octsamsung\\DRUSEN\\druse...     25     30    100   \n",
       "2    C:/Users/Sukku/Desktop/octsamsung\\CNV\\cnv_test...     25     30    100   \n",
       "3    C:/Users/Sukku/Desktop/octsamsung\\CNV\\cnv_test...     25     30    100   \n",
       "4    C:/Users/Sukku/Desktop/octsamsung\\CNV\\cnv_test...     25     30    100   \n",
       "..                                                 ...    ...    ...    ...   \n",
       "477  C:/Users/Sukku/Desktop/octsamsung\\DRUSEN\\druse...     25     30    100   \n",
       "478  C:/Users/Sukku/Desktop/octsamsung\\DRUSEN\\druse...     25     30    100   \n",
       "479  C:/Users/Sukku/Desktop/octsamsung\\DRUSEN\\druse...     25     30    100   \n",
       "480  C:/Users/Sukku/Desktop/octsamsung\\CNV\\cnv_test...     25     30    100   \n",
       "481  C:/Users/Sukku/Desktop/octsamsung\\DRUSEN\\druse...     25     30    100   \n",
       "\n",
       "     y_max   class  \n",
       "0      150  DRUSEN  \n",
       "1      150  DRUSEN  \n",
       "2      150     CNV  \n",
       "3      150     CNV  \n",
       "4      150     CNV  \n",
       "..     ...     ...  \n",
       "477    150  DRUSEN  \n",
       "478    150  DRUSEN  \n",
       "479    150  DRUSEN  \n",
       "480    150     CNV  \n",
       "481    150  DRUSEN  \n",
       "\n",
       "[482 rows x 6 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1=pd.read_csv('train_annotations.csv')\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3d850341",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torchvision\n",
    "# from torchvision.models.detection import FasterRCNN\n",
    "# from torchvision.models.detection.rpn import AnchorGenerator\n",
    "\n",
    "# # Load a pre-trained model for classification and return only the features\n",
    "# backbone = torchvision.models.mobilenet_v2(pretrained=True).features\n",
    "# backbone.out_channels = 1280\n",
    "\n",
    "# # Anchor generator\n",
    "# anchor_generator = AnchorGenerator(sizes=((32, 64, 128, 256, 512),), aspect_ratios=((0.5, 1.0, 2.0),))\n",
    "\n",
    "# # RoI pooler\n",
    "# roi_pooler = torchvision.ops.MultiScaleRoIAlign(featmap_names=['0'], output_size=7, sampling_ratio=2)\n",
    "\n",
    "# # Put the pieces together inside a FasterRCNN model\n",
    "# model = FasterRCNN(backbone,\n",
    "#                    num_classes=3,  # including background\n",
    "#                    rpn_anchor_generator=anchor_generator,\n",
    "#                    box_roi_pool=roi_pooler)\n",
    "# from tensorflow.keras.backend import clear_session\n",
    "# clear_session()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4e368d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "# from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import backend as tf\n",
    "# from keras_preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f027197e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model parameters\n",
    "img_height, img_width = 224, 224  # Adjust image size based on your dataset\n",
    "num_classes = 2  # Drusen (1) or CNV (2)\n",
    "epochs = 10\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "084899b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
      "9406464/9406464 [==============================] - 2s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# Load pre-trained MobileNetV2 base model\n",
    "mobilenet = MobileNetV2(input_shape=(img_height, img_width, 3), weights=\"imagenet\", include_top=False)\n",
    "mobilenet.trainable = False  # Freeze base model weights for transfer learning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0ef67283",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define input layer\n",
    "inputs = Input(shape=(img_height, img_width, 3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8c249ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass input through base model\n",
    "x = mobilenet(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c280853f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add custom head for Faster R-CNN\n",
    "x = Flatten()(x)\n",
    "x = Dense(128, activation=\"relu\")(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(num_classes, activation=\"softmax\")(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "106e7847",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model outputs\n",
    "outputs = [x]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f0c65477",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Faster R-CNN model\n",
    "model = Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a3310975",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define optimizer\n",
    "optimizer = Adam(learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "186785dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a04d4c27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 689 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Load the CSV files for training, validation, and test datasets\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    \"C:/Users/Sukku/Desktop/octsamsung\",\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=32,\n",
    "    class_mode=\"binary\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa02912",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "9cd830fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 689 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    \"C:/Users/Sukku/Desktop/octsamsung\",\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=32,\n",
    "    class_mode=\"binary\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "a458b663",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 689 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    \"C:/Users/Sukku/Desktop/octsamsung\",\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=32,\n",
    "    class_mode=\"binary\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "109cfcf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "21/21 [==============================] - 22s 1s/step - loss: 8.1940 - accuracy: 0.4384 - val_loss: 256.0820 - val_accuracy: 1.0000\n",
      "Epoch 2/5\n",
      "21/21 [==============================] - 23s 1s/step - loss: 8.0468 - accuracy: 0.4871 - val_loss: 252.4005 - val_accuracy: 1.0000\n",
      "Epoch 3/5\n",
      "21/21 [==============================] - 24s 1s/step - loss: 8.1449 - accuracy: 0.4384 - val_loss: 254.3687 - val_accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "21/21 [==============================] - 23s 1s/step - loss: 8.0713 - accuracy: 0.5358 - val_loss: 253.9060 - val_accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "21/21 [==============================] - 24s 1s/step - loss: 8.1694 - accuracy: 0.6104 - val_loss: 253.4957 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x23380067710>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // 32,\n",
    "    epochs=5,\n",
    "    validation_data=val_generator,\n",
    "    validation_steps=val_generator.samples // 32,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "2f4e847f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 7s 343ms/step - loss: 255.8029 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[255.8028564453125, 1.0]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the model on the test data\n",
    "model.evaluate(test_generator, steps=test_generator.samples // 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6fed34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save the model for future use\n",
    "# model.save(\"/path/to/model.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
